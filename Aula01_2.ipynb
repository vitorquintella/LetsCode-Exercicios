{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-DaiNtivGXGT"
   },
   "source": [
    "# Árvores\n",
    "\n",
    "Na aula de hoje, vamos explorar os seguintes tópicos em Python:\n",
    "\n",
    "- 1) Introdução\n",
    "- 2) Árvores de decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-2S9ac5GXGX"
   },
   "source": [
    "<img src=\"https://miro.medium.com/max/899/0*Wy3QjtXL9qf-Ssyz.jpg\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4KfYRwHcGXGY"
   },
   "source": [
    "###  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7GE2mXGGXGY"
   },
   "source": [
    "## Árvores de Decisão\n",
    "\n",
    "Para começar vamos entender qual é a estrutura de uma árvore de decisão:\n",
    "\n",
    "<img src=\"https://i1.wp.com/www.vooo.pro/insights/wp-content/uploads/2016/12/RDS-Vooo_insights-Tutorial_arvore_de_decisao_02.jpg?resize=640%2C371&ssl=1\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnGKO8jjGXGZ"
   },
   "source": [
    "###  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZN9Cxn2GXGZ"
   },
   "source": [
    "**Alguns exemplos de aplicações de Árvores de Decisão:** <br>\n",
    "\n",
    "<img src=\"https://web.tecnico.ulisboa.pt/ana.freitas/bioinformatics.ath.cx/bioinformatics.ath.cx/uploads/RTEmagicC_arv_dec4_01.gif.gif\" width=500>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<img src=\"https://didatica.tech/wp-content/uploads/2020/07/image-3.png\" width=500>\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRDnDTfEGXGZ"
   },
   "source": [
    "Quando trabalhamos com múltiplas variáveis, como definir qual variável vamos utilizar primeiro para o Nó?\n",
    "\n",
    "Vamos utilizar o exemplo de uma amostra de 30 alunos com duas variáveis: Sexo (menino ou menina), Classe (IX ou X). Além disso 15 dos 30 alunos jogam tênis no intervalo. Dado isso, a pergunta que fica é: **Qual variável/feature utilizar para fazer a quebra do nó raiz: sexo ou classe?**\n",
    "\n",
    "Há duas possibilidades de quebras:\n",
    "\n",
    "<img src=\"https://i2.wp.com/www.vooo.pro/insights/wp-content/uploads/2016/12/RDS-Vooo-Tutorial_completo_arvore_decisao_03.jpg?resize=617%2C293&ssl=1\" width=500>\n",
    "\n",
    "Vemos que, **dependendo da feature que utilizamos pra fazer a quebra**, conseguimos **graus de separações diferentes dos dados com relação ao target**.\n",
    "\n",
    "Como decidir então, qual das quebras acima **separou melhor os dados com relação ao target?**\n",
    "\n",
    "Matematicamente, o modelo pode usar dois critérios diferentes para decidir como fazer as quebras na árvore: o **critério de Gini** ou o **critério da entropia**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yboJObV-GXGa"
   },
   "source": [
    "###  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qpy_3cspGXGb"
   },
   "source": [
    "### **Critério de Gini**\n",
    "\n",
    "A **impureza de Gini** mede o quão \"impuras\" são as folhas das árvores construídas após as quebras nos nós. O coeficiente é dado por:\n",
    "\n",
    "$$Gini(D) = 1 - \\sum{p_{i}^2}$$\n",
    "\n",
    "Onde $p_i$ são as proporções de separação do target em cada quebra.\n",
    "\n",
    "OBS:   \n",
    "- É **PROPORÇÃO** e **NÃO PROBABILIDADE**. Proporção eu tenho certeza, probabilidade não.  \n",
    "- Indíce zero(0) é um nó puro\n",
    "    - Todos os elementos são da mesma classe  \n",
    "  \n",
    "Aqui estaremos interessados **em como a impureza muda após as quebras**. Nosso objetivo será **maximizar a purificação proporcionada pela quebra nos nós** -- mais precisamente, estamos interessados em determinar **qual é a quebra que proporciona a maior purificação**.\n",
    "\n",
    "<table>\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th colspan=\"4\"><center>Sexo</center></th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td colspan=\"2\"><center>Meninas</center></td>\n",
    "    <td colspan=\"2\"><center>Meninos</center></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><center>jogam tênis</center></td>\n",
    "    <td><center>NÃO jogam tênis</center></td>\n",
    "    <td><center>jogam tênis</center></td>\n",
    "    <td><center>NÃO jogam tênis</center></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><center>2</center></td>\n",
    "    <td><center>8</center></td>\n",
    "    <td><center>13</center></td>\n",
    "    <td><center>7</center></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td colspan=\"2\"><center>10</center></td>\n",
    "    <td colspan=\"2\"><center>20</center></td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "\n",
    "- **Impureza antes da divisão**: Como não havia separação alguma, a impureza era dada simplesmente pelo balanço natural dos dados: \n",
    "\n",
    "$$G(\\text{pré-divisão}) = 1 - ((15/30)^2 + (15/30)^2) = 0.5$$\n",
    "\n",
    "Temos duas quebras possíveis:\n",
    "\n",
    "- Divisão por **sexo**: após a divisão dos dados pela feature **sexo**, passamos a ter as seguintes impurezas, segundo a tabela acima: \n",
    "\n",
    "    - $G(\\text{meninas}) = 1 - (\\frac{2}{10}^2 + \\frac{8}{10}^2) = 0.319$\n",
    "    \n",
    "    - $G(\\text{meninos}) = 1 - ( \\frac{13}{20}^2 + \\frac{7}{20}^2) = 0.454$\n",
    "    \n",
    "    Ou seja, após a divisão, a impureza total passa a ser a média ponderada: \n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    - $G(\\text{pós-divisão}) = \\frac{10}{30} \\times G(\\text{meninas}) + \\frac{20}{30} \\times G(\\text{meninos})\n",
    "    = 0.33 \\times 0.319 + 0.66 \\times 0.454\n",
    "    = 0.40491$\n",
    "    \n",
    "    Assim, **a perda de impureza proporcionada pela quebra** dos dados segundo a feature **sexo** é de:\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    - $\\Delta G_{\\text{sexo}} = G(\\text{pré-divisão}) - G(\\text{pós-divisão}) = 0.5 - 0.40491 = $ **0.095**\n",
    "    \n",
    "    \n",
    "<br> \n",
    "\n",
    "<table>\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th colspan=\"4\"><center>Classe</center></th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td colspan=\"2\"><center>Classe IX</center></td>\n",
    "    <td colspan=\"2\"><center>Classe X</center></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><center>jogam tênis</center></td>\n",
    "    <td><center>NÃO jogam tênis</center></td>\n",
    "    <td><center>jogam tênis</center></td>\n",
    "    <td><center>NÃO jogam tênis</center></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><center>6</center></td>\n",
    "    <td><center>8</center></td>\n",
    "    <td><center>9</center></td>\n",
    "    <td><center>7</center></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td colspan=\"2\"><center>14</center></td>\n",
    "    <td colspan=\"2\"><center>16</center></td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "- Divisão por **classe**: após a divisão dos dados pela feature **classe**, passamos a ter as seguintes impurezas, segundo a tabela acima:\n",
    "\n",
    "    - $G(\\text{IX}) = 1 - (\\frac{6}{14}^2 + \\frac{8}{14}^2) = 0.489$\n",
    "    \n",
    "    - $G(\\text{X}) = 1 - ( \\frac{9}{16}^2 + \\frac{7}{16}^2) = 0.492$\n",
    "    \n",
    "    Ou seja, após a divisão, a impureza total passa a ser a média ponderada: \n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    - $G(\\text{pós-divisão}) = \\frac{14}{30} \\times G(\\text{IX}) + \\frac{16}{30} \\times G(\\text{X})\n",
    "    = 0.46 \\times 0.489 + 0.53 \\times 0.492\n",
    "    = 0.4857$\n",
    "    \n",
    "    Assim, **a perda de impureza proporcionada pela quebra** dos dados segundo a feature **classe** é de:\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    - $\\Delta G_{\\text{classe}} = G(\\text{pré-divisão}) - G(\\text{pós-divisão}) = 0.5 - 0.4857 = $ **0.014**\n",
    "  \n",
    "Agora, como escolher a melhor quebra?\n",
    "\n",
    "> O **critério de Gini** consiste em **escolher a quebra que proporciona a maior perda de impureza**, ou, equivalentemente, **a maior purificação**.\n",
    "\n",
    "Assim, a divisão a ser escolhida seria por **sexo**. \n",
    "\n",
    "Depois, aplica-se o mesmo procedimento para os nós resultantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8I_roJYHGXGc"
   },
   "source": [
    "###  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTwKnC57GXGd"
   },
   "source": [
    "### **Critério de entropia**\n",
    "\n",
    "A **entropia** é uma quantidade definida em física e teoria da informação com o objetivo de quantificar **o grau de desordem de um sistema**, ou, equivalentemente, **o quanto de informação se tem sobre determinado sistema**.\n",
    "\n",
    "A entropia é dada por:\n",
    "\n",
    " $$E = -\\sum{p_{i} \\times \\log_{2}{p_{i}}}$$\n",
    " \n",
    " \n",
    "Onde $p_i$ são as proporções de separação do target em cada quebra.\n",
    "\n",
    "Aqui estaremos interessados **em como a impureza muda após as quebras**. \n",
    " \n",
    "Aqui também estaremos interessados **em como a entropia muda após as quebras**. Nosso objetivo será **maximizar o ganho de informação proporcionado pela quebra nos nós** -- mais precisamente, estamos interessados em determinar **qual é a quebra que proporciona o maior ganho de informação**.\n",
    "\n",
    "- **Entropia antes da divisão**: \n",
    "\n",
    "$$E(pré-divisão) = -1 \\times (\\frac{15}{30}log_{2}{\\frac{15}{30}} + \\frac{15}{30}log_{2}{\\frac{15}{30}}) = 1$$\n",
    "\n",
    "\n",
    "Temos duas quebras possíveis:\n",
    "\n",
    "- Divisão por sexo: \n",
    "\n",
    "    - $E(\\text{meninas}) = -1 \\times (\\frac{2}{10} \\log_{2}\\frac{2}{10} + \\frac{8}{10} \\log_{2}\\frac{8}{10}) = 0.721$\n",
    "    - $E(\\text{meninos}) = -1 \\times (\\frac{13}{20} \\log_{2}\\frac{13}{20} + \\frac{7}{20} \\log_{2}\\frac{7}{20}) = 0.934$\n",
    "    \n",
    "    A entropia ponderada após a divisão por **sexo** é:\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    - $E(\\text{pós-divisão}) = \\frac{10}{30} \\times E(\\text{meninas}) + \\frac{20}{30} \\times E(\\text{meninos}) =  0.863$\n",
    "    \n",
    "    Assim, o ganho de informação após a divisão por **sexo** é:\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    - $\\Delta E_{\\text{sexo}} = E(\\text{pré-divisão}) - E(\\text{pós-divisão}) = 1 - 0.863 =$ **0.137**\n",
    "\n",
    "<br>\n",
    "\n",
    "- Divisão por classe:\n",
    "\n",
    "    - $E(\\text{IX}) = -1 \\times (\\frac{6}{14} \\log_{2}\\frac{6}{14} + \\frac{8}{14} \\log_{2}\\frac{8}{14}) = 0.985$\n",
    "    - $E(\\text{X}) = -1 \\times (\\frac{9}{16} \\log_{2}\\frac{9}{16} + \\frac{7}{16} \\log_{2}\\frac{7}{16}) = 0.988$\n",
    "    \n",
    "    A entropia ponderada após a divisão por **classe** é:\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    - $E(\\text{pós-divisão}) = \\frac{14}{30} \\times E(\\text{IX}) + \\frac{16}{30} \\times E(\\text{X}) =  0.986$\n",
    "    \n",
    "    Assim, o ganho de informação após a divisão por **classe** é:\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    - $\\Delta E_{\\text{classe}} = E(\\text{pré-divisão}) - E(\\text{pós-divisão}) = 1 - 0.986 =$ **0.014**\n",
    "\n",
    "Também pela entropia, a divisão a ser escolhida seria por **sexo**. \n",
    "\n",
    "Depois, **aplica-se o mesmo procedimento para os nós resultantes, até obter-se nós puros**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXzLeZWVGXGd"
   },
   "source": [
    "###  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1n0JYooPGXGd"
   },
   "source": [
    "A **diferença do Gini e da Entropia** é minimamente computacional, e olhando para o lado do resultado do modelo apesar das medidas poderem ser semelhantes.\n",
    "\n",
    "E qual critério utilizar? (Caso encontre novas referências compartilhe)  \n",
    "https://www.unine.ch/files/live/sites/imi/files/shared/documents/papers/Gini_index_fulltext.pdf\n",
    "- We found that they disagree only in 2% of all cases\n",
    "- Calcular log é mais caro computacionalmente\n",
    "- A \"vantagem\" logaritmica é justamente quando o valor percorre uma gama grande de valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6p5ZJ12GXGe"
   },
   "source": [
    "###  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-M1BR__GXGe"
   },
   "source": [
    "### Exemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uqn6bSbHGXGe"
   },
   "source": [
    "Vamos a nosso exemplo prático?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T21:44:37.669368Z",
     "start_time": "2020-02-16T21:44:32.974848Z"
    },
    "id": "x50uFKIqGXGe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2o6tuysGXGf"
   },
   "source": [
    "Para esse exemplo iremos utilizar um dataset sobre [Heart Failure](https://www.kaggle.com/andrewmvd/heart-failure-clinical-data), para ter mais detalhes sobre a base de dados, podemos dar uma olhada na documentação no Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CbjMi8-KGXGf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1IPu8LFGXGi"
   },
   "source": [
    "Documentação para o [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "of_DbzAtGXGi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gv1ZPQNOGXGj"
   },
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1YXsM0mGXGj"
   },
   "source": [
    "## Revisão - Métricas de Avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWx8aQJKGXGj"
   },
   "source": [
    "Um importante processo durante a modelagem e termos alguma forma de avalairmos a qaulidade do que modelamos, e para isso utlizamos de **métricas de avaliação**.\n",
    "\n",
    "No caso de problemas de classificação, existem **métricas específicas**, e também um importante conceito chamado de **Matriz de Confusão**.\n",
    "\n",
    "A **matriz de confusão** leva em consideração as **classes preditas** e as **classes verdadeiras** da base de **teste**, e contabiliza a performance do modelo:\n",
    "\n",
    "<img src=https://diegonogare.net/wp-content/uploads/2020/04/matrizConfusao-600x381.png height=\"400\" width=\"400\">\n",
    "\n",
    "No Sklearn, a notação muda um pouco:\n",
    "\n",
    "<img src=\"https://static.packt-cdn.com/products/9781838555078/graphics/C13314_06_05.jpg\" width=400>\n",
    "\n",
    "Note que a diagonal principal são as observações que o modelo acertou! Temos:\n",
    "\n",
    "- Verdadeiros Positivos (VP): classificação correta da classe positivo;\n",
    "- Verdadeiros Negativos (VN): classificação correta da classe negativo;\n",
    "- Falsos Positivos (FP, erro tipo I): correto: negativo. Previsto: positivo.\n",
    "- Falsos Negativos (FN, erro tipo II): correto: positivo. Previsto: negativo.\n",
    "\n",
    "Um jeito fácil de lembrar os tipos de erros:\n",
    "\n",
    "\n",
    "<img src=\"https://i.pinimg.com/originals/f6/9b/11/f69b111014ef466fe541a393346d2c3a.jpg\" height=\"400\" width=\"400\">\n",
    "\n",
    "\n",
    "Visto isso, as seguintes métricas numéricas de avaliação são bastante comuns na avaliação de modelos de classificação:\n",
    "\n",
    "- Acurácia (Accuracy): porcentagem de classificações CORRETAS do modelo;\n",
    "\n",
    "- Precisão (Precision): das respostas retornadas, quantas são relevantes? -- é a razão entre verdadeiros positivos e o  número de **preditos positivos**, isto é, positivos quanto à **label predita pelo modelo**.\n",
    "\n",
    "- Revocação/Sensibilidade (Recall/Sensitivity): das respostas relevantes, quantas são retornadas? -- é a razão entre verdadeiros positivos e o  número de **verdadeiramente positivos**, isto é, positivos quanto à **label real**.\n",
    "\n",
    "- F1-Score: média harmônica de precision e recall.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/1200px-Precisionrecall.svg.png\" width=450>\n",
    "\n",
    "Devido ao <a href=\"https://medium.com/opex-analytics/why-you-need-to-understand-the-trade-off-between-precision-and-recall-525a33919942\">tradeoff entre precision e recall</a>, a métrica a ser otimizada é o F1! \n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1080/1*t1vf-ofJrJqtmam0KSn3EQ.png\" height=\"400\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G_9cAOMDGXGk",
    "outputId": "a4e21768-e8c9-4047-9822-a7050cbe1e7a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOgXXX8SGXGk"
   },
   "source": [
    "Para os modelos de árvores, conseguimos plotar como que fica a quebra nos Nós:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9YVciRjFGXGk",
    "outputId": "fbdadd86-62b2-4fc4-c42f-cada0062b8b3",
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAMgFXY8GXGo"
   },
   "source": [
    "###  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos mexer no parâmetro de profundidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88_uHVHDGXGp"
   },
   "source": [
    "## Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BxKjXisAGXGp"
   },
   "source": [
    "__1)__ Use os dados do Titanic.\n",
    "Crie uma arvore de decisão se os passageiros vão sobreviver ou não. (Cuidado com a idade em anos/meses)\n",
    "\n",
    "Para pegar os dados, use: https://www.kaggle.com/c/titanic/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jByW_eU1GXGp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "r1YXsM0mGXGj",
    "iCN8RqlDGXGm",
    "GAMgFXY8GXGo",
    "88_uHVHDGXGp"
   ],
   "name": "Aula 2.1 - Árvores.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
